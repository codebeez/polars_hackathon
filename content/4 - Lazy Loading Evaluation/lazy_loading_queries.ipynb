{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import time\n",
    "from content.utils import polars_read_tsv_file\n",
    "\n",
    "DATASET_FILE = \"content/data/imdb_dataset/{file}\"\n",
    "\n",
    "def read_imdb_tsv_file(filename_stem):\n",
    "    return polars_read_tsv_file(DATASET_FILE + f\"{filename_stem}\")\n",
    "\n",
    "def scan_imdb_tsv_file(filename_stem):\n",
    "    return pl.scan_csv(DATASET_FILE + f\"{filename_stem}\")\n",
    "\n",
    "def read_imdb_parquet_file(filename_stem):\n",
    "    return pl.read_parquet(DATASET_FILE + f\"{filename_stem}.parquet\")\n",
    "\n",
    "def scan_imdb_parquet_file(filename_stem):\n",
    "    return pl.scan_parquet(DATASET_FILE + f\"{filename_stem}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV in Polars\n",
    "\n",
    "In Polars, files can be read directly into memory just as in Pandas.\n",
    "Users of Pandas might know that there is an option to provide a selection of columns you want to read to save resources.\n",
    "Polars, however, takes this a bit further.\n",
    "In Polars you have a lazy loading option, which permits scanning files instead of reading them directly into memory.\n",
    "This creates an instance of a `LazyFrame` instead of a `DataFrame`.\n",
    "The scanning operation keeps a reference to the file, while permitting users to define any processing of the data without ever reading the file.\n",
    "The file conents are then only read when the user finally collects the data by calling `LazyFrame.collect()`.\n",
    "As a consequence, Polars can reorder any operations performed on the `LazyFrame` to create an optimal query plan, which often allows for much faster processing with a significantly lower memory usage.\n",
    "\n",
    "Let us read the file containing all movie titles from the IMDB dataset and inspect the first 15 titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "movie_titles = read_imdb_tsv_file(\"title.basics\")\n",
    "print(f\"{time.time() - start_time} seconds for Polars\")\n",
    "display(movie_titles.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this takes quite a bit of time.\n",
    "What if we only scan the file, filter the first 15 items and only then collect the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "movie_titles = scan_imdb_tsv_file(\"title.basics\")\n",
    "print(f\"{time.time() - start_time} seconds for Polars\")\n",
    "display(movie_titles.head(15).collect())\n",
    "del movie_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, much better!\n",
    "The scanning operation and the consequent slicing operation to select the first 15 items allows Polars to only read partially read the file and return the 15 rows as soon as they have been read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would Pandas do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "movies_pandas = pd.read_csv(DATASET_FILE.format(file=\"title.basics.tsv\"), sep=\"\\t\")\n",
    "movies_pandas.head(15)\n",
    "print(f\"{time.time() - start_time} seconds for Pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I want to watch a good movie!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the knowledge we obtained above, let's only scan the movies and the corresponding ratings (defined in a separate file).\n",
    "To find the movies that are the best according to the users who rated, we will have to join the two together.\n",
    "Polars defines joins on this with different join strategy types which most of you will know from databases theory and any packages that deal with data.\n",
    "Apart from `left`, `right`, `inner`, `outer` and `cross` joins, the `semi` and `anti` join are also available in Polars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2\n",
    "Create a ranking of the 20 best movies according to the user ratings using the `LazyFrame` instance.\n",
    "For this, you will have to join the ratings with the movie data.\n",
    "Don't forget the number of votes, or your ranking will be worthless.\n",
    "Can you get close to the official IMDB ranking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = read_imdb_tsv_file(\"title.basics\")\n",
    "ratings = read_imdb_tsv_file(\"title.ratings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3\n",
    "\n",
    "Let's take it one step further!\n",
    "Can we find the 20 actors whose known-for movies are the highest ranking movies on average?\n",
    "Again, do not forget to take the number of votes into account as well!\n",
    "For this you may have to `explode()` the data frame and may additionally need to `split()` a column with comma-separated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors = scan_imdb_tsv_file(\"name.basics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last query is likely quite a complex one, it can provide a nice example for the query optimization of Polars.\n",
    "If you did not manage to do the last one or skipped it, you can also do this with the query from before.\n",
    "In that case, if the query is already optimal, you may want to reverse the order or introduce some extra (unnecessary) statements, such as additional sorting operations before the final sort.\n",
    "\n",
    "The LazyFrame, also sometimes referred to as a query as it builds up the query through the operations the user defines on the object, provides insights in how queries are built up and how Polars automatically optimizes the query for us before collecting the data.\n",
    "These insights can be obtained through the `explain` method, which gives an overview of the query steps in text, or through the `show_graph` method, which gives a visual overview of the steps through an extra extension, as shown below.\n",
    "For both of these methods you can pass in `True` or `False` for the parameter `optimized` in order to compare the optimized with the naive query plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.4\n",
    "Use the `explain()` and `show_graph()` method on the `LazyFrame` instance constructed in the last exercise to compare the optimized query with the naive one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet files\n",
    "\n",
    "CSV (or TSV) files are easy to work with, human-readable and supported by a wide range of different tools (if you have to work with people who only want to deal with Excel...).\n",
    "However, it is typically not the most efficient format for storing data.\n",
    "One of the reasons is that data is stored in row-based fashion, which does not allow us to efficiently read only required columns.\n",
    "Apart from that, there is no compression and intelligent rearrangement of data to avoid having to read only a certain portion of it.\n",
    "\n",
    "This is where Parquet comes in!\n",
    "Parquet is a file format which originates from an open-source project under the Apache Software Foundation (hence the full name Apache Parquet).\n",
    "In contrast to CSV, the format is a columnar-storage format.\n",
    "This change also opened up possibilities for column-based encoding and compression, which now allows for optimal techniques for the types contained in the column, which is stored along with the contents itself.\n",
    "\n",
    "Let's use Polars to read in the CSV files and convert them to Parquet files!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.5\n",
    "#### Exercise 4.5.1\n",
    "Convert the title.ratings and the name.basics files to Parquet files using Polars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4.5.2 \n",
    "Would there be any speed difference if we now perform the same operations as above on the CSV files to obtain a list of the best-ranked movies?\n",
    "Rewrite exercise 4.2 to use the Parquet files instead and measure the difference in execution time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = read_imdb_parquet_file(\"title.basics\")\n",
    "ratings = read_imdb_parquet_file(\"title.ratings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = scan_imdb_parquet_file(\"title.basics\")\n",
    "ratings = scan_imdb_parquet_file(\"title.ratings\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
