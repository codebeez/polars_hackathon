{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "687c8139",
   "metadata": {},
   "source": [
    "# Sentiment Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33359128",
   "metadata": {},
   "source": [
    "In this last part of the hackathon, we will train a small deep learning model on the IMDB Sentiment dataset.\n",
    "This dataset contains review texts along with a labelled \"positive\" or \"negative\" sentiment.\n",
    "We will preprocess the data using Polars, which you will implement.\n",
    "We will then train and evaluate a neural network that can predict a sentiment for an arbitrary input text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a001b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9315d7f8",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "First of all we will load the data.\n",
    "It is always a good idea to visualise a portion of the data and do a few sanity checks before starting the preprocessing.\n",
    "\n",
    "### Exercise 5.1\n",
    "#### Exercise 5.1.1\n",
    "Load the data using polars.\n",
    "Since in this case we are going to process all the data at once, we can read it in directly rather than scanning and collecting separate parts in our analysis.\n",
    "However, a golden tip is that it is still always a good idea convert the DataFrame to a LazyFrame to allow the optimization engine to optimize all the queries we define subsequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac09bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pl.read_csv(\"content/data/imdb_sentiment_dataset/IMDB_Dataset.csv\")\n",
    "data = data.lazy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc42d6",
   "metadata": {},
   "source": [
    "#### Exercise 5.1.2\n",
    "Using only Polars, show the number of records in the dataset, (separately) visualise the first few records and the last few records of the data and show the counts per sentiment value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c570bdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>len</th></tr><tr><td>u32</td></tr></thead><tbody><tr><td>50000</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 1)\n",
       "┌───────┐\n",
       "│ len   │\n",
       "│ ---   │\n",
       "│ u32   │\n",
       "╞═══════╡\n",
       "│ 50000 │\n",
       "└───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>review</th><th>sentiment</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;One of the other reviewers has…</td><td>&quot;positive&quot;</td></tr><tr><td>&quot;A wonderful little production.…</td><td>&quot;positive&quot;</td></tr><tr><td>&quot;I thought this was a wonderful…</td><td>&quot;positive&quot;</td></tr><tr><td>&quot;Basically there&#x27;s a family whe…</td><td>&quot;negative&quot;</td></tr><tr><td>&quot;Petter Mattei&#x27;s &quot;Love in the T…</td><td>&quot;positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────────────────┬───────────┐\n",
       "│ review                          ┆ sentiment │\n",
       "│ ---                             ┆ ---       │\n",
       "│ str                             ┆ str       │\n",
       "╞═════════════════════════════════╪═══════════╡\n",
       "│ One of the other reviewers has… ┆ positive  │\n",
       "│ A wonderful little production.… ┆ positive  │\n",
       "│ I thought this was a wonderful… ┆ positive  │\n",
       "│ Basically there's a family whe… ┆ negative  │\n",
       "│ Petter Mattei's \"Love in the T… ┆ positive  │\n",
       "└─────────────────────────────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>review</th><th>sentiment</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;I thought this movie did a dow…</td><td>&quot;positive&quot;</td></tr><tr><td>&quot;Bad plot, bad dialogue, bad ac…</td><td>&quot;negative&quot;</td></tr><tr><td>&quot;I am a Catholic taught in paro…</td><td>&quot;negative&quot;</td></tr><tr><td>&quot;I&#x27;m going to have to disagree …</td><td>&quot;negative&quot;</td></tr><tr><td>&quot;No one expects the Star Trek m…</td><td>&quot;negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────────────────┬───────────┐\n",
       "│ review                          ┆ sentiment │\n",
       "│ ---                             ┆ ---       │\n",
       "│ str                             ┆ str       │\n",
       "╞═════════════════════════════════╪═══════════╡\n",
       "│ I thought this movie did a dow… ┆ positive  │\n",
       "│ Bad plot, bad dialogue, bad ac… ┆ negative  │\n",
       "│ I am a Catholic taught in paro… ┆ negative  │\n",
       "│ I'm going to have to disagree … ┆ negative  │\n",
       "│ No one expects the Star Trek m… ┆ negative  │\n",
       "└─────────────────────────────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sentiment</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;negative&quot;</td><td>25000</td></tr><tr><td>&quot;positive&quot;</td><td>25000</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────────┬───────┐\n",
       "│ sentiment ┆ count │\n",
       "│ ---       ┆ ---   │\n",
       "│ str       ┆ u32   │\n",
       "╞═══════════╪═══════╡\n",
       "│ negative  ┆ 25000 │\n",
       "│ positive  ┆ 25000 │\n",
       "└───────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.select(pl.len()).collect())\n",
    "display(data.head().collect())\n",
    "display(data.tail().collect())\n",
    "display(data.collect()[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c24e1",
   "metadata": {
    "id": "a3de2414"
   },
   "source": [
    "## Preprocessing\n",
    "In case of a larger dataset, it may be a good idea to use the `tf.Dataset` interface to allow preprocessing portions of the data in parallel with training on the data that has already been preprocessed, which can be accomplished through the `map()` function.\n",
    "In this case, our dataset is relatively small and we can do the full preprocessing beforehand.\n",
    "\n",
    "First off, for the training procedure we will want to use integer values for our labels.\n",
    "In the case of binary values, mapping to 0 and 1 is most commonly used.\n",
    "\n",
    "### Exercise 5.2\n",
    "Convert the sentiment column in the data frame by mapping positive reviews to the value 1 and negative reviews to the value 0.\n",
    "Display the first few records to assure that the conversion was done correctly, then display the value counts to assure that the column now only consists of 0 and 1 values and that the counts are identical to before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01cd598d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>review</th><th>sentiment</th></tr><tr><td>str</td><td>i8</td></tr></thead><tbody><tr><td>&quot;One of the other reviewers has…</td><td>1</td></tr><tr><td>&quot;A wonderful little production.…</td><td>1</td></tr><tr><td>&quot;I thought this was a wonderful…</td><td>1</td></tr><tr><td>&quot;Basically there&#x27;s a family whe…</td><td>0</td></tr><tr><td>&quot;Petter Mattei&#x27;s &quot;Love in the T…</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────────────────┬───────────┐\n",
       "│ review                          ┆ sentiment │\n",
       "│ ---                             ┆ ---       │\n",
       "│ str                             ┆ i8        │\n",
       "╞═════════════════════════════════╪═══════════╡\n",
       "│ One of the other reviewers has… ┆ 1         │\n",
       "│ A wonderful little production.… ┆ 1         │\n",
       "│ I thought this was a wonderful… ┆ 1         │\n",
       "│ Basically there's a family whe… ┆ 0         │\n",
       "│ Petter Mattei's \"Love in the T… ┆ 1         │\n",
       "└─────────────────────────────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>review</th><th>sentiment</th></tr><tr><td>str</td><td>i8</td></tr></thead><tbody><tr><td>&quot;I thought this movie did a dow…</td><td>1</td></tr><tr><td>&quot;Bad plot, bad dialogue, bad ac…</td><td>0</td></tr><tr><td>&quot;I am a Catholic taught in paro…</td><td>0</td></tr><tr><td>&quot;I&#x27;m going to have to disagree …</td><td>0</td></tr><tr><td>&quot;No one expects the Star Trek m…</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────────────────┬───────────┐\n",
       "│ review                          ┆ sentiment │\n",
       "│ ---                             ┆ ---       │\n",
       "│ str                             ┆ i8        │\n",
       "╞═════════════════════════════════╪═══════════╡\n",
       "│ I thought this movie did a dow… ┆ 1         │\n",
       "│ Bad plot, bad dialogue, bad ac… ┆ 0         │\n",
       "│ I am a Catholic taught in paro… ┆ 0         │\n",
       "│ I'm going to have to disagree … ┆ 0         │\n",
       "│ No one expects the Star Trek m… ┆ 0         │\n",
       "└─────────────────────────────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sentiment</th><th>count</th></tr><tr><td>i8</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>25000</td></tr><tr><td>1</td><td>25000</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────────┬───────┐\n",
       "│ sentiment ┆ count │\n",
       "│ ---       ┆ ---   │\n",
       "│ i8        ┆ u32   │\n",
       "╞═══════════╪═══════╡\n",
       "│ 0         ┆ 25000 │\n",
       "│ 1         ┆ 25000 │\n",
       "└───────────┴───────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.with_columns(\n",
    "    pl.col(\"sentiment\").replace({\"positive\": 1, \"negative\": 0}).cast(pl.Int8)\n",
    ")\n",
    "display(data.head().collect())\n",
    "display(data.tail().collect())\n",
    "display(data.collect()[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b13a248",
   "metadata": {},
   "source": [
    "### Exercise 5.3\n",
    "Split the data into two distinct sets of train and test data respectively.\n",
    "Visualise the output shapes to ensure that the ratio between the two is as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1d9df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-11 14:52:29.256250: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-11 14:52:30.668022: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-11 14:52:31.739745: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-11 14:52:32.588342: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-11 14:52:32.809849: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-11 14:52:34.512323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 14:52:57.421628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a0a93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data.collect(), test_size=0.2, random_state=42)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03025ca",
   "metadata": {},
   "source": [
    "## Tokenize the review texts\n",
    "An important concept in natural language processing is tokenization.\n",
    "As individual characters have little meaning and would yield an extremely high-dimensional search space, texts are instead tokenized into common sequences of characters.\n",
    "For LLM's such as GPT, the tokenization is nowadays commonly done character-based.\n",
    "However, especially for smaller models it is a good idea to use whole words as tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc3b739",
   "metadata": {},
   "source": [
    "### Exercise 5.4\n",
    "Use the keras Tokenizer (already imported for your convenience) to tokenize our input data.\n",
    "#### Exercise 5.4.1\n",
    "Instantiate the Tokenizer and fit it on the review texts of our **training data** using the `fit_on_texts()` method.\n",
    "In this manner, the Tokenizer will determine how to tokenize data based on the provided fitting data.\n",
    "You can directly pass in the Polars Series object, as it implements the required iterator for said method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf3e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_data[\"review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3619bc9d",
   "metadata": {},
   "source": [
    "#### Exercise 5.4.2\n",
    "Subsequently, convert the reviews from our training and test data to create the final input data (X) to use for training and testing.\n",
    "Display the resulting arrays to ensure that the text was tokenized and to get a rough idea of the input for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65572a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  43,   10,   13, ...,  205,  351, 3856],\n",
       "       [  21,  103,    1, ...,   89,  103,    9],\n",
       "       [   0,    0,    0, ...,    2,  710,   62],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1641,    2,  603],\n",
       "       [   0,    0,    0, ...,  245,  103,  125],\n",
       "       [   0,    0,    0, ...,   70,   73, 2062]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  995,  719,  155],\n",
       "       [  12,   59,  196, ...,  380,    7,    7],\n",
       "       [   0,    0,    0, ...,   50, 1088,   96],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,  125,  200, 3241],\n",
       "       [   0,    0,    0, ..., 1066,    1, 2305],\n",
       "       [   0,    0,    0, ...,    1,  332,   27]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_x = pad_sequences(tokenizer.texts_to_sequences(train_data[\"review\"]), maxlen=250)\n",
    "test_x = pad_sequences(tokenizer.texts_to_sequences(test_data[\"review\"]), maxlen=250)\n",
    "display(train_x)\n",
    "display(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74f773",
   "metadata": {},
   "source": [
    "#### Exercise 5.4.3\n",
    "Convert our training and test labels to numpy arrays.\n",
    "Again inspect both arrays to ensure the content is roughly as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba4e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data.get_column(\"sentiment\").to_numpy()\n",
    "test_y = test_data.get_column(\"sentiment\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98430129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 1], dtype=int8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb33e93",
   "metadata": {},
   "source": [
    "## Defining and compiling the model\n",
    "Here we build and train the model.\n",
    "The model we will be using is a small model, and it looks simple because Keras defined a great deal for us.\n",
    "Although the model itself is outside of the scope of this hackathon, of course I'll give a brief explanation of the different parts.\n",
    "The Embedding layer defines takes the sparse input data and embeds it into a lower-dimensional space that is easier for our model to work with.\n",
    "The output of this layer is passed into the LSTM (Long Short-Term Memory) submodel, which is a model consisting of multiple layers internally, designed to learn how to relate sequential data (e.g. words in a sentence).\n",
    "Finally, the output of the LSTM is passed into a Dense layer with a Sigmoid activation function.\n",
    "This layer will give a continuous output between 0 and 1.\n",
    "During the training phase, we will use the loss function (\"binary cross-entropy\" as defined below) to steer the model towards predicting a score close to 0 for the labels we defined as 0, and 1 for the labels we defined as 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8f76251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/polars_hackathon/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=250))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879d2243",
   "metadata": {
    "id": "5ef6b455"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d911a57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 203ms/step - accuracy: 0.7300 - loss: 0.5322 - val_accuracy: 0.8364 - val_loss: 0.3819\n",
      "Epoch 2/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 222ms/step - accuracy: 0.8538 - loss: 0.3541 - val_accuracy: 0.8555 - val_loss: 0.3497\n",
      "Epoch 3/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 211ms/step - accuracy: 0.8611 - loss: 0.3359 - val_accuracy: 0.5599 - val_loss: 1.4974\n",
      "Epoch 4/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 207ms/step - accuracy: 0.7727 - loss: 0.4740 - val_accuracy: 0.8865 - val_loss: 0.2733\n",
      "Epoch 5/5\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 213ms/step - accuracy: 0.9151 - loss: 0.2193 - val_accuracy: 0.8955 - val_loss: 0.2641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f756451cd70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=5, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a4316",
   "metadata": {},
   "source": [
    "## Save the model and tokenizer\n",
    "We save the model and tokenizer to be able to load them for a different purpose or in a later phase.\n",
    "For the remainder of this notebook, however, we will keep using the instances we have here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2919f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tokenizer.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"model.h5\")\n",
    "joblib.dump(tokenizer, \"tokenizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8c53a",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06ac9b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 53ms/step - accuracy: 0.8947 - loss: 0.2590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2591925859451294, 0.8938000202178955]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27493a8f",
   "metadata": {},
   "source": [
    "## Use the model to predict the sentiment for a review\n",
    "### Exercise 5.5\n",
    "Define a function that takes a review text as input and uses the tokenizer to convert the text to a token sequence, pad it similarly to the input data and finally provide it as input for our model.\n",
    "Then read the output and convert it to a \"positive\" or \"negative\" string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc0d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment_for_review(review):\n",
    "    sequences = tokenizer.texts_to_sequences([review])\n",
    "    padded_review_sequences = pad_sequences(sequences, maxlen=250)\n",
    "    positive_score = model.predict(padded_review_sequences)[0][0]\n",
    "    return (\n",
    "        \"positive\" if positive_score >= 0.5 else \"negative\"\n",
    "    )  # You might want to fine-tune this threshold on a new dataset if the data distribution changes and retraining is too expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b3c94d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment_for_review(\"I'd rather watch paint dry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d38b87f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment_for_review(\"The best movie I've ever seen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cae7834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment_for_review(\"Absolutely stunning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dbd3348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment_for_review(\"Even The Titanic was better...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5171d3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment_for_review(\"sucks\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
